<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="keywords" content=""><meta name="description" content=""><meta name="Robots" content="all"><title>Hexo</title><link rel="icon" href="/images/icon.svg"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/atom-one-dark.css"><link rel="stylesheet" href="/css/style.css"><script src="/js/highlight.min.js"></script><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml"></head><body><div class="main-container"><header class="header"><div class="global-width"><nav class="nav-box"><a class="nav-item" href="/">主页</a> <a class="nav-item" href="/resume">项目</a> <a class="nav-item" href="/mood" target="_blank">心情</a> <a class="nav-item" href="/amusement/tetris" target="_blank">简历</a> <a class="nav-item" href="/fuye.md">关于</a></nav></div></header><section class="content global-width"><div class="main"><article class="box post post-item"><div class="post-title"><a href="/2019/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B9%8BTFIDF/">文本特征提取之TF-IDF</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-26</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B9%8BTFIDF/"><p>TF-IDF 是一种加权技术。采用一种统计方法，根据字词在文本中出现的次数和在整个语料中出现的文档频率来计算一个字词在整个语料中的重要程度。 主要思想：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。 作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度 优点：能过滤掉一些常见的却无关紧要的词语，同时保留影响整个文本的重要词语。</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2019/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91/">机器学习之决策树</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-25</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91/"><p>决策树认识决策树 决策树思想的来源非常朴素，程序设计中的条件分支结构就是if-then结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法 信息的单位：比特bite</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2019/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/">机器学习之朴素贝叶斯算法</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-25</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/"><p>朴素贝叶斯算法概率基础 联合概率 定义：包含多个条件，且所有条件同时成立的概率。 记作：P(A,B) P(A,B) = P(A)P(B)</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2019/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E4%B9%8B%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81%EF%BC%88One-Hot)/">机器学习：数据预处理之One-Hot编码</a></div><div class="post-meta"><span class="label">转载</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-16</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E4%B9%8B%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81%EF%BC%88One-Hot)/"><p>数据预处理之独热编码(One-Hot）转载https://www.imooc.com/article/35900在机器学习算法中，我们经常会遇到分类特征，例如：人的性别有男女，祖国有中国，美国，法国等。这些特征值并不是连续的，而是离散的，无序的。通常我们需要对其进行特征数字化。 那什么是特征数字化呢？例子如下：</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2019/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/">机器学习之特征预处理</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-15</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/"><p>特征预处理通过特定的统计方法(数学方法)将数据转化成算法要求的数据 数值型数据 标准缩放： 1.归一化 2.标准化 3.缺失值 类别型数据 one-hot 编码 关于one-hot编码：https://blog.csdn.net/weixin_43170863/article/details/100184168 时间类型 时间的切分 sklearn特征处理API sklearn.preprocessing</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2019/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BD%AC%E5%8C%96%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8/">转化器和估计器</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-15</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BD%AC%E5%8C%96%E5%99%A8%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8/"><p>转化器和估计器转化器 fit():输入数据但不做事情，就是计算平均值，方差等等 transform(): 通过fit产生的平均值和方差转换数据 fit_transform() = fit() + transform() 估计器</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2019/07/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8Bk-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/">机器学习之k-近邻算法</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-08</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8Bk-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/"><p>k-近邻算法(KNN) 定义：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。 来源：KNN算法最早由Cover和Hart提出的一种分类算法。</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2019/07/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB/">机器学习算法分类</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2019-07-05</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2019/07/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB/"><p>机器学习算法分类监督学习(特征值+目标值)</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div></article></div><div class="aside"><div class="box widget"><div class="introduction"><p><img src="/images/ironman.jpg" alt="head-sculpture"></p><p class="name">罗明辉Eric</p><p class="slogan">个人博客，分享经验，分享快乐</p></div></div><div class="box widget"><div class="title">最新</div><ul class="item-box"><li><a href="/2020/09/03/ETL/Kettle/">Kettle</a></li><li><a href="/2020/08/10/BI/Tebleau/">Tebleau</a></li><li><a href="/2020/08/05/BI/PowerBI/">PowerBI</a></li><li><a href="/2020/07/28/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL%E8%AF%AD%E5%8F%A5%E8%B0%83%E4%BC%98/">SQL语句调优</a></li><li><a href="/2020/07/25/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E5%8E%9F%E7%90%86/">Mysql底层原理</a></li><li><a href="/2020/07/15/BigDataFrame/HBase%E5%85%A5%E9%97%A8/">HBase入门</a></li><li><a href="/2020/07/05/BigDataFrame/Hive%E9%AB%98%E9%98%B6/">Hive高阶</a></li><li><a href="/2020/07/01/BigDataFrame/Hive%E5%85%A5%E9%97%A8/">Hive入门</a></li></ul></div><div class="box widget"><div class="title">分类</div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BI%E5%B7%A5%E5%85%B7/">BI工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ETL%E5%B7%A5%E5%85%B7/">ETL工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a><span class="category-list-count">1</span></li></ul></div><div class="box widget"><div class="title">归档</div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">2020-09</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">2020-08</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">2020-07</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">2020-06</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">2020-01</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">2019-12</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">2019-07</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">2019-03</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">2018-09</a><span class="archive-list-count">1</span></li></ul></div></div></section><footer class="footer"><div class="global-width footer-box"><div class="copyright"><span>Copyright &copy; 2020</span> <span class="dotted">|</span> <span>Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a></span> <span class="dotted">|</span> <span>Theme by <a href="javascript:">Luominghui</a></span> <span class="dotted">|</span></div></div></footer></div><script>hljs.initHighlightingOnLoad()</script></body></html>