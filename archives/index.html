<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="keywords" content=""><meta name="description" content=""><meta name="Robots" content="all"><title>Eric个人博客</title><link rel="icon" href="/images/icon.svg"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/atom-one-dark.css"><link rel="stylesheet" href="/css/style.css"><script src="/js/highlight.min.js"></script><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Eric个人博客" type="application/atom+xml"></head><body><div class="main-container"><header class="header"><div class="global-width"><nav class="nav-box"><a class="nav-item" href="/">主页</a> <a class="nav-item" href="/resume">项目</a> <a class="nav-item" href="/mood" target="_blank">热点观点</a> <a class="nav-item" href="/2018/01/01/introduce/" target="_blank">个人介绍</a> <a class="nav-item" href="/fuye.md">关于</a></nav></div></header><section class="content global-width"><div class="main"><article class="box post post-item"><div class="post-title"><a href="/2020/11/24/BigDataFrame/Kylin/">Kylin</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-11-24</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/11/24/BigDataFrame/Kylin/"><p>Kylin空间换时间 一、概述1. 定义Apache Kylin是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表。 2. 特点(1) 标准SQL接口 (2) 支持超大数据集 (3) 亚秒级响应 (4) 可伸缩性和高吞吐率 (5) BI工具集成 ODBC JDBC RestAPI 3. 架构 (1) REST ServerREST Server是一套面向应用程序开发的入口点，旨在实现针对Kylin平台的应用开发工作。 此类应用程序可以提供查询、获取结果、触发cube构建任务、获取元数据以及获取用户权限等等。另外可以通过Restful接口实现SQL查询。 (2) Query Engine当cube准备就绪后，查询引擎就能够获取并解析用户查询。它随后会与系统中的其它组件进行交互，从而向用户返回对应的结果。 (3) Routing在最初设计时曾考虑过将Kylin不能执行的查询引导去Hive中继续执行，但在实践后发现Hive与Kylin的速度差异过大，导致用户无法对查询的速度有一致的期望，很可能大多数查询几秒内就返回结果了，而有些查询则要等几分钟到几十分钟，因此体验非常糟糕。最后这个路由功能在发行版中默认关闭。 (4) MetadataKylin是一款元数据驱动型应用程序。元数据管理工具是一大关键性组件，用于对保存在Kylin当中的所有元数据进行管理，其中包括最为重要的cube元数据。其它全部组件的正常运作都需以元数据管理工具为基础。 Kylin的元数据存储在hbase中。 (5) Cube Build Engine这套引擎的设计目的在于处理所有离线任务，其中包括shell脚本、Java API以及Map Reduce任务等等。任务引擎对Kylin当中的全部任务加以管理与协调，从而确保每一项任务都能得到切实执行并解决其间出现的故障。 4. 工作原理MOLAP多维立方体分析 1. 维度和度量维度：观察数据的角度 度量：维度的统计值，就是聚合运算的结果 2. Cube和CuboidN个维度，组合就有2的n次方中 每一种维度组合就是一个Cuboid，所有Cuboid整体就是一个Cube 3. 核心算法Kylin的工作原理就是对数据模型做Cube预计算，并利用计算的结果加速查询 (1) 指定数据模型，定义维度和度量 (2) 预计算Cube，计算所有Cuboid并保存为物化视图 预计算过程是Kylin从Hive中读取原始数据，按照我们选定的维度进行计算，并将结果集保存到Hbase中，默认的计算引擎为MapReduce，可以选择Spark作为计算引擎，一次build的结果，称为Segment。构建过程中会涉及多个Cuboid的创建，具体创建过程由kylin.cube.algorithm参数决定，参数值可选auto，layer和inmem，默认值为auto，即Kylin会通过采集数据动态地选择一个算法(layer or inmem), 如果用户很了解Kylin和自身的数据、集群，可以直接设置喜欢的算法。 (3) 执行查询，读取Cuboid，运行，产生查询结果 3.1 逐层构建算法（layer） 从下向上依次执行n次MR,第一层是根据原始数据计算得出，其余层是根据上一层的结果得出。 每一轮的计算都是MR任务，且串行执行；一个N维的Cude,至少需要N次MR Job 算法优点(1) 此算法充分利用MapReduce的能力，处理了中间复杂的排序和洗牌工作，故而算法代码清晰简单，易于维护； (2) 受益于Hadoop的日趋成熟，此算法对集群要求低，运行稳定；在内部维护Kylin的过程中，很少遇到在这几步出错的情况；即便是在Hadoop集群比较繁忙的时候，任务也能完成。 算法缺点(1) 当Cube有很多维度的时候，所需要的MapReduce任务也相应增加；由于Hadoop的任务调度需要耗费额外资源，特别是集群较庞大的时候，反复递交任务造成的额外开销会相当可观； (2) 由于Mapper不做预聚合，此算法会对Hadoop MapReduce输出较多数据；虽然已经使用了Combiner来减少从Mapper端到Reducer端的数据传输，所有数据依然需要通过Hadoop MapReduce来排序和组合才能被聚合，无形之中增加了集群的压力 (3) 对HDFS的读写操作较多：由于每一层计算的输出会用作下一层计算的输入，这颗Key-Value需要写到HDFS上；当所有计算都完成后，Kylin还需要额外的一轮任务将这些文件转成HBase的HFile格式，以导入到HBase中去； 总体而言，该算法的效率较低，尤其是当Cube维度数较大的时候 3.2 快速构建算法（inmem) 也被称作“逐段”(By Segment) 或“逐块”(By Split) 算法，从1.5.x开始引入该算法，该算法的主要思想是，每个Mapper将其所分配到的数据块，计算成一个完整的小Cube 段（包含所有Cuboid）。每个Mapper将计算完的Cube段输出给Reducer做合并，生成大Cube，也就是最终结果。如图所示解释了此流程。 无论多少维度，都是一个MR Job完成 与旧算法相比，两点不同： (1) Mapper会利用内存做预聚合，算出所有组合；Mapper输出的每个Key都是不同的，这样会减少输出到Hadoop MapReduce的数据量，Combiner也不再需要； (2) 一轮Map Reduce便会完成所有层次的计算，减少Hadoop任务的调配。 二、环境搭建三、创建项目1. 创建工程2. 选择数据源3. 创建Model4. 创建Cube5. 增量设置四、数据可视化-BI工具集成五、Cube构建优化问题：假设有20个维度就会有2的20次方个Cuboid，对构建引擎、存储引擎都会产生很大的压力。 解决：在构建维度数量较多的Cube时，要注意Cube的剪枝优化（即减少Cuboid的生成） (1) Cube中的维度数量较多，且没有进行很好的Cuboid剪枝优化，导致Cuboid数量很多； (2) Cube中存在较高基数的维度，导致包含这类维度的每一个Cuboid占用的空间都很大，这些Cuboid累积造成整体Cube体积变大 优化1. 使用聚合组假设A、B、C三个维度 (1) 强制维度(Mandatory Dimensions) ​ 强制A维度必须存在 ​ 0、A、AB、AC、ABC (2) 层级维度(Hierarchy Dimensions) ​ A、B是层级关系，那么就B就不能单独出现 ​ 0、A、C、AB、AC、ABC (3) 联合维度(Joint Dimensions) ​ A、B作为联合维度，AB必须同出现 ​ 0、C、AB、ABC 2. 并发粒度优化当Segment中某一个Cuboid的大小超出一定的阈值时，系统会将该Cuboid的数据分片到多个分区中，以实现Cuboid数据读取的并行化，从而优化Cube的查询速度。具体的实现方式如下：构建引擎根据Segment估计的大小，以及参数“kylin.hbase.region.cut”的设置决定Segment在存储引擎中总共需要几个分区来存储，如果存储引擎是HBase，那么分区的数量就对应于HBase中的Region数量。kylin.hbase.region.cut的默认值是5.0，单位是GB，也就是说对于一个大小估计是50GB的Segment，构建引擎会给它分配10个分区。用户还可以通过设置kylin.hbase.region.count.min（默认为1）和kylin.hbase.region.count.max（默认为500）两个配置来决定每个Segment最少或最多被划分成多少个分区。 由于每个Cube的并发粒度控制不尽相同，因此建议在Cube Designer 的Configuration Overwrites（上图所示）中为每个Cube量身定制控制并发粒度的参数。假设将把当前Cube的kylin.hbase.region.count.min设置为2，kylin.hbase.region.count.max设置为100。这样无论Segment的大小如何变化，它的分区数量最小都不会低于2，最大都不会超过100。相应地，这个Segment背后的存储引擎（HBase）为了存储这个Segment，也不会使用小于两个或超过100个的分区。我们还调整了默认的kylin.hbase.region.cut，这样50GB的Segment基本上会被分配到50个分区，相比默认设置，我们的Cuboid可能最多会获得5倍的并发量。</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/11/13/BigDataFrame/Flink/">Flink</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-11-13</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/11/13/BigDataFrame/Flink/"><p>Flink好家伙，现在的项目要用到Flink，所以开始修仙学习，及时更博</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/11/05/BigDataFrame/canal/">Canal</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-11-05</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/11/05/BigDataFrame/canal/"><p>一、介绍MySQL 数据库增量日志并解析binlog日志，提供增量数据订阅和消费 二、使用场景 数据库镜像 数据库实时备份 索引构建和实时维护(拆分异构索引、倒排索引等) 业务 cache 刷新 带业务逻辑的增量数据处理 跨数据库的数据备份(异构数据库同步)，mysql==&gt;oracle，mysql==&gt;mongo, mysql==&gt;redis, mysql==&gt;elasticsearch 三、工作原理</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/09/26/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E6%A8%A1/">数据仓库-建模</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-09-26</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/09/26/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E6%A8%A1/"><p>数据仓库-建模方法一、基本概念OLTP系统建模方法 OLTP(在线事务处理)系统中，主要操作是随机读写 为了保证数据的一致性、减少冗余，常使用关系模型 在关系模型中，常使用3NF来减少冗余 OLAP系统1.基本概念 OLAP系统，主要操作是复杂分析查询；关注数据聚合，以及分析、处理性能 OLAP根据数据存储方法不同，又分为ROLAP、MOLAP、HOLAP</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/09/20/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/">数据仓库-架构</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-09-20</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/09/20/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/"><p>数据仓库架构一、架构图 二、ETLExtract-Transform-Load 将数据从来源端经过抽取（extract）、交互转换（transform）、加载（load）至目的端的过程 构建数据仓库的重要一环，用户从数据源抽取出所需的数据，经过数据清洗，最终按照预先定义好的数据仓库模型，将数据加载到数据仓库中去 ETL 规则的设计和实施约占整个数据仓库搭建工作量的 60%～80%</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/09/19/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%A6%82%E8%BF%B0/">数据仓库-概述</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-09-19</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/09/19/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%A6%82%E8%BF%B0/"><p>数据仓库概述1. 概念 数据仓库是一个面向主题的、集成的、非易失的且随时间变化的数据集合 主要用于组织积累的历史数据，并使用分析方法（OLAP、数据分析）进行分析整理，进而辅助决策，为管理者、企业系统提供数据支持，构建商业智能。 2. 特点1.面向主题为数据分析提供服务，根据主题将原始数据集合在一起 2.集成</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/09/18/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-09-18</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/09/18/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"><p>数据仓库一、简介数据仓库（Data Warehouse）简称DW或DWH，是数据库的一种概念上的升级，可以说是为满足新需求设计的一种新数据库，而这个数据库是需容纳更多的数据，更加庞大的数据集，从逻辑上讲数据仓库和数据库是没有什么区别的。为企业所有级别的决策制定过程，提供所有类型数据支撑的战略集合，主要是用于数据挖掘和数据分析，以建立数据沙盘为基础，为消灭消息孤岛和支持决策为目的而创建的。 二、数据仓库分层1. ODS层（原始数据层）存放原始数据，直接加载原始日志、数据，数据保持原貌不做处理 2. DWD层（明细数据层）结构和粒度与原始表保持一致，对ODS层数据进行清洗（去除空值，脏数据，超过极限范围的数据) 3. DWS层（服务数据层）进行轻度汇总 4. ADS层（数据应用层）</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/09/10/BigDataFrame/YARN/">YARN</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-09-10</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/09/10/BigDataFrame/YARN/"><p>YARN ResourceManager作用 处理客户端请求 监控NodeManager 启动或监控ApplicationMaster 资源的分配和调度 负责处理客户端请求，对各NodeManager上的资源进行统一管理和调度。给ApplicationMaster分配空闲的Container运行并监控其运行状态。主要由两个组件构成：调度器和应用程序管理器 1. 调度器(Scheduler)调度器根据容量、队列等限制条件，将系统中的资源分配给各个正在运行的应用程序。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配的单位是Container。Scheduler不负责监控或者跟踪应用程序的状态。总之，调度器根据应用程序的资源要求，以及集群机器的资源情况，为应用程序分配封装在Container中的资源。</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/09/06/BigDataFrame/HDFS%E8%81%94%E9%82%A6%E6%9C%BA%E5%88%B6/">HDFS联邦机制</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-09-06</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/09/06/BigDataFrame/HDFS%E8%81%94%E9%82%A6%E6%9C%BA%E5%88%B6/"><p>HDFS联邦机制概述单NameNode的架构使得HDFS在集群扩展和性能上都有潜在的问题，当集群大到一定程度后，NameNode进程使用的内存可能达到上百G。NameNode成为了性能的瓶颈。因此提出了NameNode水平扩展方案-Federation。 多个NameNode意味着有多个namespace,区别于HA模式下的NameNode,他们是拥有着同一个NameSpace.</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a></div></article><article class="box post post-item"><div class="post-title"><a href="/2020/09/05/BigDataFrame/HDFS%E9%AB%98%E5%8F%AF%E7%94%A8/">HDFS高可用机制</a></div><div class="post-meta"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-09-05</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric</div><div class="post-excerpt"><a href="/2020/09/05/BigDataFrame/HDFS%E9%AB%98%E5%8F%AF%E7%94%A8/"><p>HDFS高可用机制一、概述由于HDFS中最重要的就是NameNode,所以NameNode的可用性直接决定了Hadoop的可用性，一旦NameNode进程不能工作，就会影响集群的正常运行。 在典型的HA集群中，两台独立的机器被配置为NameNode。在工作集群中，NameNode机器中的一个处于Active状态，另一个处于Standby状态。 二、工作要点1.元数据管理方式需要改变</p></a></div><div class="post-footer"><i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a></div></article><nav class="page-nav"><span class="page-number current">1</span><a class="page-number" href="/archives/page/2/">2</a><a class="page-number" href="/archives/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/archives/page/5/">5</a><a class="extend next" rel="next" href="/archives/page/2/">Next</a></nav></div><div class="aside"><div class="box widget"><div class="introduction"><p><img src="/images/ironman.jpg" alt="head-sculpture"></p><p class="name">罗明辉Eric</p><p class="slogan">个人博客，分享经验，分享快乐</p></div></div><div class="box widget"><div class="title">最新</div><ul class="item-box"><li><a href="/2020/11/24/BigDataFrame/Kylin/">Kylin</a></li><li><a href="/2020/11/13/BigDataFrame/Flink/">Flink</a></li><li><a href="/2020/11/05/BigDataFrame/canal/">Canal</a></li><li><a href="/2020/09/26/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E6%A8%A1/">数据仓库-建模</a></li><li><a href="/2020/09/20/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/">数据仓库-架构</a></li><li><a href="/2020/09/19/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%A6%82%E8%BF%B0/">数据仓库-概述</a></li><li><a href="/2020/09/18/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></li><li><a href="/2020/09/10/BigDataFrame/YARN/">YARN</a></li></ul></div><div class="box widget"><div class="title">分类</div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BI%E5%B7%A5%E5%85%B7/">BI工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ETL%E5%B7%A5%E5%85%B7/">ETL工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a><span class="category-list-count">1</span></li></ul></div><div class="box widget"><div class="title">归档</div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">2020-11</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">2020-09</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">2020-07</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">2020-06</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">2020-05</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">2020-01</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">2019-12</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">2019-07</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">2019-03</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">2018-09</a><span class="archive-list-count">1</span></li></ul></div></div></section><footer class="footer"><div class="global-width footer-box"><div class="copyright"><span>Copyright &copy; 2020</span> <span class="dotted">|</span> <span>Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a></span> <span class="dotted">|</span></div></div></footer></div><script>hljs.initHighlightingOnLoad()</script></body></html>