<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="author" content="Eric"><meta name="keywords" content=""><meta name="description" content="第一章 HBase简介 / 第二章 HBase安装 / 第三章 HBase Shell操作 /第四章 HBase数据结构 / 第五章 HBase原理 / 第六章 HBase API操作


HBase第一章 HBase简介1.1 什么是HBase  HBase是一种分布式、可扩展、支持海量数据..."><meta name="Robots" content="all"><title>Hexo | HBase入门</title><link rel="icon" href="/images/icon.svg"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/atom-one-dark.css"><link rel="stylesheet" href="/css/style.css"><script src="/js/highlight.min.js"></script><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml"></head><body><div class="main-container"><header class="header"><div class="global-width"><nav class="nav-box"><a class="nav-item" href="/">主页</a> <a class="nav-item" href="/resume">项目</a> <a class="nav-item" href="/mood" target="_blank">热点观点</a> <a class="nav-item" href="/2018/01/01/introduce/" target="_blank">个人介绍</a> <a class="nav-item" href="/fuye.md">关于</a></nav></div></header><section class="content global-width"><div class="main"><article class="box post"><div class="post-title align-center detail-title">HBase入门</div><div class="post-meta align-center"><span class="label">原创</span> <span class="dotted">|</span> <i class="fa fa-calendar"></i> <time>2020-07-15</time> <span class="dotted">|</span> <i class="fa fa-user"></i> Eric <span class="dotted">|</span> <i class="fa fa-folder-open-o"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a></div><div class="post-content"><p>第一章 HBase简介 / 第二章 HBase安装 / 第三章 HBase Shell操作 /<br>第四章 HBase数据结构 / 第五章 HBase原理 / 第六章 HBase API操作</p><a id="more"></a><h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h3 id="第一章-HBase简介"><a href="#第一章-HBase简介" class="headerlink" title="第一章 HBase简介"></a>第一章 HBase简介</h3><h4 id="1-1-什么是HBase"><a href="#1-1-什么是HBase" class="headerlink" title="1.1 什么是HBase"></a>1.1 什么是HBase</h4><p>HBase是一种分布式、可扩展、支持海量数据存储的NoSQL数据库。</p><h4 id="1-2-HBase特点"><a href="#1-2-HBase特点" class="headerlink" title="1.2 HBase特点"></a>1.2 HBase特点</h4><p>(1) <strong>海量存储</strong>：适合存储PB级别的海量数据，在PB级别的数据以及采用廉价PC存储的情况下，能在几十到几百毫秒内返回数据。这与Hbase的极易扩展性息息相关。正式因为Hbase良好的扩展性，才为海量数据的存储提供了便利。</p><p>(2) <strong>列式存储</strong>：这里的列式存储其实说的是<font color="red">列族（ColumnFamily）存储</font>，Hbase是根据列族来存储数据的。列族下面可以有非常多的列，列族在创建表的时候就必须指定。</p><p>(3) <strong>极易扩展</strong>：Hbase的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer）的扩展，一个是基于存储的扩展（HDFS）。</p><p>通过横向添加RegionSever的机器，进行水平扩展，提升Hbase上层的处理能力，提升Hbsae服务更多Region的能力。</p><p>备注：RegionServer的作用是管理region、承接业务的访问，这个后面会详细的介绍通过横向添加Datanode的机器，进行存储层扩容，提升Hbase的数据存储能力和提升后端存储的读写能力。</p><p>(4) <strong>高并发（多核）</strong>：由于目前大部分使用Hbase的架构，都是采用的廉价PC，因此单个IO的延迟其实并不小，一般在几十到上百ms之间。这里说的高并发，主要是在并发的情况下，Hbase的单个IO延迟下降并不多。能获得高并发、低延迟的服务。</p><p>(5) <strong>稀疏</strong>：稀疏主要是针对Hbase列的灵活性，在列族中，你可以指定任意多的列，在列数据为空的情况下，是不会占用存储空间的。</p><h4 id="1-3-HBase架构"><a href="#1-3-HBase架构" class="headerlink" title="1.3 HBase架构"></a>1.3 HBase架构</h4><p><img src="https://i.loli.net/2020/10/27/BtuKpVU9rScGnyi.png"></p><p>从图中可以看出Hbase是由Client、Zookeeper、Master、HRegionServer、HDFS等几个组件组成，下面来介绍一下几个组件的相关功能：</p><p><strong>(1) Client</strong></p><p>Client包含了访问Hbase的接口，另外Client还维护了对应的cache来加速Hbase的访问，比如cache的.META.元数据的信息。</p><p><strong>(2) Zookeeper</strong></p><p>HBase通过Zookeeper来做master的高可用、RegionServer的监控、元数据的入口以及集群配置的维护等工作。具体工作如下：</p><p>通过Zoopkeeper来保证集群中只有1个master在运行，如果master异常，会通过竞争机制产生新的master提供服务</p><p>通过Zoopkeeper来监控RegionServer的状态，当RegionSevrer有异常的时候，通过回调的形式通知Master RegionServer上下线的信息</p><p>通过Zoopkeeper存储元数据的统一入口地址</p><p><strong>(3) Hmaster(NameNode)</strong></p><p>master节点的主要职责如下：<br>为RegionServer分配Region<br>维护整个集群的负载均衡<br>维护集群的元数据信息<br>发现失效的Region，并将失效的Region分配到正常的RegionServer上<br>当RegionSever失效的时候，协调对应Hlog的拆分</p><p><strong>(4) HregionServer(DataNode)</strong></p><p><font color="red">HregionServer直接对接用户的读写请求</font>，是真正的“干活”的节点。它的功能概括如下：<br>管理master为其分配的Region<br>处理来自客户端的读写请求<br>负责和底层HDFS的交互，存储数据到HDFS<br>负责Region变大以后的拆分<br>负责Storefile的合并工作</p><p><strong>(5) HDFS</strong></p><p>HDFS为Hbase提供最终的底层数据存储服务，同时为HBase提供高可用（Hlog存储在HDFS）的支持，具体功能概括如下：<br>提供元数据和表数据的底层分布式存储服务<br>数据多副本，保证的高可靠和高可用性</p><h4 id="1-3-HBase中的角色"><a href="#1-3-HBase中的角色" class="headerlink" title="1.3 HBase中的角色"></a>1.3 HBase中的角色</h4><h5 id="1-3-1-HMaster"><a href="#1-3-1-HMaster" class="headerlink" title="1.3.1 HMaster"></a>1.3.1 HMaster</h5><p><strong>功能</strong></p><p>1．监控RegionServer</p><p>2．处理RegionServer故障转移</p><p>3．处理元数据的变更</p><p>4．处理region的分配或转移</p><p>5．在空闲时间进行数据的负载均衡</p><p>6．通过Zookeeper发布自己的位置给客户端</p><h5 id="1-3-2-RegionServer"><a href="#1-3-2-RegionServer" class="headerlink" title="1.3.2 RegionServer"></a>1.3.2 RegionServer</h5><p><strong>功能</strong></p><p>1．负责存储HBase的实际数据</p><p>2．处理分配给它的Region</p><p>3．刷新缓存到HDFS</p><p>4．维护Hlog</p><p>5．执行压缩</p><p>6．负责处理Region分片</p><h5 id="1-3-3-其他组件"><a href="#1-3-3-其他组件" class="headerlink" title="1.3.3 其他组件"></a>1.3.3 其他组件</h5><p><strong>1．Write-Ahead logs</strong></p><p>HBase的修改记录，当对HBase读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做Write-Ahead logfile的文件中，然后再写入内存中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</p><p><strong>2．Region</strong></p><p>Hbase表的分片，HBase表会根据RowKey值被切分成不同的region存储在RegionServer中，在一个RegionServer中可以有多个不同的region。</p><p><strong>3．Store</strong></p><p>HFile存储在Store中，一个Store对应HBase表中的一个列族(列簇， Column Family)。</p><p><strong>4．MemStore</strong></p><p>顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在WAL中之后，RegsionServer会在内存中存储键值对。</p><p><strong>5．HFile</strong></p><p>这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。StoreFile是以Hfile的形式存储在HDFS的。</p><h3 id="第二章-HBase安装"><a href="#第二章-HBase安装" class="headerlink" title="第二章 HBase安装"></a>第二章 HBase安装</h3><h4 id="2-1-Zookeeper正常部署"><a href="#2-1-Zookeeper正常部署" class="headerlink" title="2.1 Zookeeper正常部署"></a>2.1 Zookeeper正常部署</h4><p>首先保证Zookeeper集群的正常部署，并启动之：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 zookeeper-3.4.10]$ bin/zkServer.sh start</span><br><span class="line">[atguigu@hadoop103 zookeeper-3.4.10]$ bin/zkServer.sh start</span><br><span class="line">[atguigu@hadoop104 zookeeper-3.4.10]$ bin/zkServer.sh start</span><br></pre></td></tr></table></figure><h4 id="2-2-Hadoop正常部署"><a href="#2-2-Hadoop正常部署" class="headerlink" title="2.2 Hadoop正常部署"></a>2.2 Hadoop正常部署</h4><p>Hadoop集群的正常部署并启动：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh</span><br><span class="line">[atguigu@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><h4 id="2-3-HBase的解压"><a href="#2-3-HBase的解压" class="headerlink" title="2.3 HBase的解压"></a>2.3 HBase的解压</h4><p>解压HBase到指定目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf hbase-1.3.1-bin.tar.gz -C /opt/module</span><br></pre></td></tr></table></figure><h4 id="2-4-HBase的配置文件"><a href="#2-4-HBase的配置文件" class="headerlink" title="2.4 HBase的配置文件"></a>2.4 HBase的配置文件</h4><p>修改HBase对应的配置文件</p><p>(1) hbase-env.sh修改内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line">JDK1.8需要注释</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> HBASE_MASTER_OPTS。。。。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">export</span> HBASE_REGIONSERVER_OPTS。。。</span></span><br></pre></td></tr></table></figure><p>(2) hbase-site.xml修改内容：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span>     </span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>     </span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span>   </span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span>   </span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">&lt;!-- 0.98后的新变动，之前版本没有.port,默认端口为60000 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>16000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span>   </span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	     <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span>   </span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	     <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/zookeeper-3.4.10/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>(3) regionservers:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure><p>(4) 软连接hadoop配置文件到hbase</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ ln -s /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml </span><br><span class="line">/opt/module/hbase/conf/core-site.xml</span><br><span class="line">[atguigu@hadoop102 module]$ ln -s /opt/module/hadoop-2.7.2/etc/hadoop/hdfs-site.xml </span><br><span class="line">/opt/module/hbase/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure><h4 id="2-5-HBase远程发送到其他集群"><a href="#2-5-HBase远程发送到其他集群" class="headerlink" title="2.5 HBase远程发送到其他集群"></a>2.5 HBase远程发送到其他集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ xsync hbase/ </span><br></pre></td></tr></table></figure><h4 id="2-6-HBase服务的启动"><a href="#2-6-HBase服务的启动" class="headerlink" title="2.6 HBase服务的启动"></a>2.6 HBase服务的启动</h4><ol><li>启动方式1</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ bin/hbase-daemon.sh start master</span><br><span class="line">[atguigu@hadoop102 hbase]$ bin/hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure><p><font color="red">提示</font>：如果集群之间的节点时间不同步，会导致regionserver无法启动，抛出ClockOutOfSyncException异常。</p><p><font color="red">修复提示</font>：</p><p>a、同步时间服务：参照Hadoop入门</p><p>b、属性：hbase.master.maxclockskew设置更发的值</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.maxclockskew<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>180000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Time difference of regionserver from master<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2.启动方式2</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ bin/start-hbase.sh</span><br></pre></td></tr></table></figure><p>对应的停止服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ bin/stop-hbase.sh</span><br></pre></td></tr></table></figure><h4 id="2-7-查看HBase页面"><a href="#2-7-查看HBase页面" class="headerlink" title="2.7 查看HBase页面"></a>2.7 查看HBase页面</h4><p>启动成功后，可以通过“host:port”的方式来访问HBase管理页面，例如：</p><p><a target="_blank" rel="noopener" href="http://hadoop102:16010/">http://hadoop102:16010</a></p><h3 id="第三章-HBase-Shell操作"><a href="#第三章-HBase-Shell操作" class="headerlink" title="第三章 HBase Shell操作"></a>第三章 HBase Shell操作</h3><h4 id="3-1-基本操作"><a href="#3-1-基本操作" class="headerlink" title="3.1 基本操作"></a>3.1 基本操作</h4><ol><li><p>进入HBase客户端命令行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ bin/hbase shell</span><br></pre></td></tr></table></figure></li><li><p>查看帮助命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; help</span><br></pre></td></tr></table></figure></li><li><p>查看当前数据库中有哪些表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):002:0&gt; list</span><br></pre></td></tr></table></figure></li></ol><h4 id="3-2-表的操作"><a href="#3-2-表的操作" class="headerlink" title="3.2 表的操作"></a>3.2 表的操作</h4><ol><li><p>创建表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):002:0&gt; create &#x27;student&#x27;,&#x27;info&#x27;</span><br></pre></td></tr></table></figure></li><li><p>插入数据到表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):003:0&gt; put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:sex&#x27;,&#x27;male&#x27;</span><br><span class="line">hbase(main):004:0&gt; put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:age&#x27;,&#x27;18&#x27;</span><br><span class="line">hbase(main):005:0&gt; put &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:name&#x27;,&#x27;Janna&#x27;</span><br><span class="line">hbase(main):006:0&gt; put &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:sex&#x27;,&#x27;female&#x27;</span><br><span class="line">hbase(main):007:0&gt; put &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:age&#x27;,&#x27;20&#x27;</span><br></pre></td></tr></table></figure></li><li><p>扫描查看表数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):008:0&gt; scan &#x27;student&#x27;</span><br><span class="line">hbase(main):009:0&gt; scan &#x27;student&#x27;,&#123;STARTROW =&gt; &#x27;1001&#x27;, STOPROW  =&gt; &#x27;1001&#x27;&#125;</span><br><span class="line">hbase(main):010:0&gt; scan &#x27;student&#x27;,&#123;STARTROW =&gt; &#x27;1001&#x27;&#125;</span><br></pre></td></tr></table></figure></li><li><p>查看表结构</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):011:0&gt; describe &#x27;student&#x27;</span><br></pre></td></tr></table></figure></li><li><p>更新指定字段的数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):012:0&gt; put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;,&#x27;Nick&#x27;</span><br><span class="line">hbase(main):013:0&gt; put &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:age&#x27;,&#x27;100&#x27;</span><br></pre></td></tr></table></figure></li><li><p>查看“指定行”或“指定列族：列”的数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):014:0&gt; get &#x27;student&#x27;,&#x27;1001&#x27;</span><br><span class="line">hbase(main):015:0&gt; get &#x27;student&#x27;,&#x27;1001&#x27;,&#x27;info:name&#x27;</span><br></pre></td></tr></table></figure></li><li><p>统计表数据行数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):021:0&gt; count &#x27;student&#x27;</span><br></pre></td></tr></table></figure></li><li><p>删除数据</p><p>删除某rowkey的全部数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):016:0&gt; deleteall &#x27;student&#x27;,&#x27;1001&#x27;</span><br></pre></td></tr></table></figure><p>删除某rowkey的一列数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):017:0&gt; delete &#x27;student&#x27;,&#x27;1002&#x27;,&#x27;info:sex&#x27;</span><br></pre></td></tr></table></figure></li><li><p>清空表数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):018:0&gt; truncate &#x27;student&#x27;</span><br></pre></td></tr></table></figure><p><font color="red">提示：</font>清空表的操作顺序为先disable，然后再truncate</p></li><li><p>删除表</p><p>首先需要先让该表为disable状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):019:0&gt; disable &#x27;student&#x27;</span><br></pre></td></tr></table></figure><p>然后才能drop这个表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):020:0&gt; drop &#x27;student&#x27;</span><br></pre></td></tr></table></figure><p><font color="red">提示：</font>如果直接drop表，会报错：Error: Table student is enabled. Disable it first.</p></li><li><p>变更表信息</p><p>将info列族中的数据存放3个版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):022:0&gt; alter &#x27;student&#x27;,&#123;NAME=&gt;&#x27;info&#x27;,VERSIONS=&gt;3&#125;</span><br><span class="line">hbase(main):022:0&gt; get &#x27;student&#x27;,&#x27;1001&#x27;,&#123;COLUMN=&gt;&#x27;info:name&#x27;,VERSIONS=&gt;3&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="第四章-HBase数据结构"><a href="#第四章-HBase数据结构" class="headerlink" title="第四章 HBase数据结构"></a>第四章 HBase数据结构</h3><h4 id="4-1-RowKey"><a href="#4-1-RowKey" class="headerlink" title="4.1 RowKey"></a>4.1 RowKey</h4><p>与nosql数据库们一样,RowKey是用来检索记录的主键。访问HBASE table中的行，只有三种方式：</p><p><strong>1.通过单个RowKey访问(get)</strong></p><p><strong>2.通过RowKey的range（正则）(like)</strong></p><p><strong>3.全表扫描(scan)</strong></p><p>RowKey行键 (RowKey)可以是<strong>任意字符串</strong>(最大长度是64KB，实际应用中长度一般为 10-100bytes)，在HBASE内部，RowKey保存为字节数组。存储时，数据按照RowKey的字典序(byte order)排序存储。设计RowKey时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。<font color="red">(位置相关性)</font></p><h4 id="4-2-Column-Family"><a href="#4-2-Column-Family" class="headerlink" title="4.2 Column Family"></a>4.2 Column Family</h4><p>列族：HBASE表中的每个列，都归属于某个列族。列族是表的schema的一部 分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如 courses:history，courses:math都属于courses 这个列族。</p><h4 id="4-3-Cell"><a href="#4-3-Cell" class="headerlink" title="4.3 Cell"></a>4.3 Cell</h4><p>由{rowkey, column Family:columu, version} 唯一确定的单元。<font color="red">cell中的数据是没有类型的，全部是字节码形式存贮</font>。</p><p>关键字：无类型、字节码</p><h4 id="4-4-Time-Stamp"><a href="#4-4-Time-Stamp" class="headerlink" title="4.4 Time Stamp"></a>4.4 Time Stamp</h4><p>HBASE 中通过rowkey和columns确定的为一个存贮单元称为cell。每个 cell都保存 着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是 64位整型。时间戳可以由HBASE(在数据写入时自动 )赋值，此时时间戳是精确到毫秒 的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版 本冲突，就必须自己生成具有唯一性的时间戳。每个 cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。</p><p>为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，HBASE提供 了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段 时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。</p><h4 id="4-5-命名空间"><a href="#4-5-命名空间" class="headerlink" title="4.5 命名空间"></a>4.5 命名空间</h4><p>命名空间的结构</p><p><img src="https://i.loli.net/2020/10/27/8wgkpNXH47WfjmU.png"></p><p>(1) Table：表，所有的表都是命名空间的成员，即表必属于某个命名空间，如果没有指定，则在default默认的命名空间中。</p><p>(2) RegionServer group：一个命名空间包含了默认的RegionServer Group。</p><p>(3) Permission：权限，命名空间能够让我们来定义访问控制列表ACL（Access Control List）。例如，创建表，读取表，删除，更新等等操作。</p><p>(4) Quota：限额，可以强制一个命名空间可包含的region的数量。</p><h3 id="第五章-HBase原理"><a href="#第五章-HBase原理" class="headerlink" title="第五章 HBase原理"></a>第五章 HBase原理</h3><h4 id="5-1-读流程"><a href="#5-1-读流程" class="headerlink" title="5.1 读流程"></a>5.1 读流程</h4><p><img src="https://i.loli.net/2020/10/27/JkdYl4fx7SnRPjb.png"></p><p>1）Client先访问zookeeper，从meta表读取region的位置，然后读取meta表中的数据。meta中又存储了用户表的region信息；</p><p>2）根据namespace、表名和rowkey在meta表中找到对应的region信息；</p><p>3）找到这个region对应的regionserver；</p><p>4）查找对应的region；</p><p>5）先从MemStore找数据，如果没有，再到BlockCache里面读；</p><p>6）BlockCache还没有，再到StoreFile上读(为了读取的效率)；</p><p>7）<font color="red">如果是从StoreFile里面读取的数据，不是直接返回给客户端，而是先写入BlockCache，再返回给客户端。</font></p><h4 id="5-2-写流程"><a href="#5-2-写流程" class="headerlink" title="5.2 写流程"></a>5.2 写流程</h4><p><img src="https://i.loli.net/2020/10/27/atWvhcZoDiJrbH4.png"></p><p>1）Client向HregionServer发送写请求；</p><p>2）HregionServer将数据写到HLog（write ahead log）。为了数据的持久化和恢复；</p><p>3）HregionServer将数据写到内存（MemStore）；</p><p>4）反馈Client写成功。</p><h4 id="5-3-数据flush过程"><a href="#5-3-数据flush过程" class="headerlink" title="5.3 数据flush过程"></a>5.3 数据flush过程</h4><p>1）当MemStore数据达到阈值（默认是128M，老版本是64M），将数据刷到硬盘，将内存中的数据删除，同时删除HLog中的历史数据；</p><p>2）并将数据存储到HDFS中；</p><p>3）在HLog中做标记点。</p><h4 id="5-4-数据合并过程"><a href="#5-4-数据合并过程" class="headerlink" title="5.4 数据合并过程"></a>5.4 数据合并过程</h4><p>1）当数据块达到3块，Hmaster触发合并操作，Region将数据块加载到本地，进行合并；</p><p>2）当合并的数据超过256M，进行拆分，将拆分后的Region分配给不同的HregionServer管理；</p><p>3）当HregionServer宕机后，将HregionServer上的hlog拆分，然后分配给不同的HregionServer加载，修改.META.；</p><p>4）注意：HLog会同步到HDFS。</p><h3 id="第六章-HBase-API操作"><a href="#第六章-HBase-API操作" class="headerlink" title="第六章 HBase API操作"></a>第六章 HBase API操作</h3><h4 id="6-1-环境准备"><a href="#6-1-环境准备" class="headerlink" title="6.1 环境准备"></a>6.1 环境准备</h4><p>新建项目后在pom.xml中添加依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">scope</span>&gt;</span>system<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;JAVA_HOME&#125;/lib/tools.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="6-2-HBase-API"><a href="#6-2-HBase-API" class="headerlink" title="6.2 HBase API"></a>6.2 HBase API</h4><h5 id="6-2-1-获取Configuration-对象"><a href="#6-2-1-获取Configuration-对象" class="headerlink" title="6.2.1 获取Configuration 对象"></a>6.2.1 获取Configuration 对象</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Configuration conf;</span><br><span class="line"><span class="keyword">static</span>&#123;</span><br><span class="line">	<span class="comment">//使用HBaseConfiguration的单例方法实例化</span></span><br><span class="line">	conf = HBaseConfiguration.create();</span><br><span class="line">conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;192.168.9.102&quot;</span>);</span><br><span class="line">conf.set(<span class="string">&quot;hbase.zookeeper.property.clientPort&quot;</span>, <span class="string">&quot;2181&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-2-判断表是否存在"><a href="#6-2-2-判断表是否存在" class="headerlink" title="6.2.2 判断表是否存在"></a>6.2.2 判断表是否存在</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isTableExist</span><span class="params">(String tableName)</span> <span class="keyword">throws</span> MasterNotRunningException,</span></span><br><span class="line"><span class="function"> ZooKeeperConnectionException, IOException</span>&#123;</span><br><span class="line">	<span class="comment">//在HBase中管理、访问表需要先创建HBaseAdmin对象</span></span><br><span class="line"><span class="comment">//Connection connection = ConnectionFactory.createConnection(conf);</span></span><br><span class="line"><span class="comment">//HBaseAdmin admin = (HBaseAdmin) connection.getAdmin();</span></span><br><span class="line">	HBaseAdmin admin = <span class="keyword">new</span> HBaseAdmin(conf);</span><br><span class="line">	<span class="keyword">return</span> admin.tableExists(tableName);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-3-创建表"><a href="#6-2-3-创建表" class="headerlink" title="6.2.3 创建表"></a>6.2.3 创建表</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String tableName, String... columnFamily)</span> <span class="keyword">throws</span></span></span><br><span class="line"><span class="function"> MasterNotRunningException, ZooKeeperConnectionException, IOException</span>&#123;</span><br><span class="line">	HBaseAdmin admin = <span class="keyword">new</span> HBaseAdmin(conf);</span><br><span class="line">	<span class="comment">//判断表是否存在</span></span><br><span class="line">	<span class="keyword">if</span>(isTableExist(tableName))&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;表&quot;</span> + tableName + <span class="string">&quot;已存在&quot;</span>);</span><br><span class="line">		<span class="comment">//System.exit(0);</span></span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="comment">//创建表属性对象,表名需要转字节</span></span><br><span class="line">		HTableDescriptor descriptor = <span class="keyword">new</span> HTableDescriptor(TableName.valueOf(tableName));</span><br><span class="line">		<span class="comment">//创建多个列族</span></span><br><span class="line">		<span class="keyword">for</span>(String cf : columnFamily)&#123;</span><br><span class="line">			descriptor.addFamily(<span class="keyword">new</span> HColumnDescriptor(cf));</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//根据对表的配置，创建表</span></span><br><span class="line">		admin.createTable(descriptor);</span><br><span class="line">		System.out.println(<span class="string">&quot;表&quot;</span> + tableName + <span class="string">&quot;创建成功！&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-4-删除表"><a href="#6-2-4-删除表" class="headerlink" title="6.2.4 删除表"></a>6.2.4 删除表</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dropTable</span><span class="params">(String tableName)</span> <span class="keyword">throws</span> MasterNotRunningException,</span></span><br><span class="line"><span class="function"> ZooKeeperConnectionException, IOException</span>&#123;</span><br><span class="line">	HBaseAdmin admin = <span class="keyword">new</span> HBaseAdmin(conf);</span><br><span class="line">	<span class="keyword">if</span>(isTableExist(tableName))&#123;</span><br><span class="line">		admin.disableTable(tableName);</span><br><span class="line">		admin.deleteTable(tableName);</span><br><span class="line">		System.out.println(<span class="string">&quot;表&quot;</span> + tableName + <span class="string">&quot;删除成功！&quot;</span>);</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;表&quot;</span> + tableName + <span class="string">&quot;不存在！&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-5-向表中插入数据"><a href="#6-2-5-向表中插入数据" class="headerlink" title="6.2.5 向表中插入数据"></a>6.2.5 向表中插入数据</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addRowData</span><span class="params">(String tableName, String rowKey, String columnFamily, String</span></span></span><br><span class="line"><span class="function"><span class="params"> column, String value)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">	<span class="comment">//创建HTable对象</span></span><br><span class="line">	HTable hTable = <span class="keyword">new</span> HTable(conf, tableName);</span><br><span class="line">	<span class="comment">//向表中插入数据</span></span><br><span class="line">	Put put = <span class="keyword">new</span> Put(Bytes.toBytes(rowKey));</span><br><span class="line">	<span class="comment">//向Put对象中组装数据</span></span><br><span class="line">	put.add(Bytes.toBytes(columnFamily), Bytes.toBytes(column), Bytes.toBytes(value));</span><br><span class="line">	hTable.put(put);</span><br><span class="line">	hTable.close();</span><br><span class="line">	System.out.println(<span class="string">&quot;插入数据成功&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-6-删除多行数据"><a href="#6-2-6-删除多行数据" class="headerlink" title="6.2.6 删除多行数据"></a>6.2.6 删除多行数据</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteMultiRow</span><span class="params">(String tableName, String... rows)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">	HTable hTable = <span class="keyword">new</span> HTable(conf, tableName);</span><br><span class="line">	List&lt;Delete&gt; deleteList = <span class="keyword">new</span> ArrayList&lt;Delete&gt;();</span><br><span class="line">	<span class="keyword">for</span>(String row : rows)&#123;</span><br><span class="line">		Delete delete = <span class="keyword">new</span> Delete(Bytes.toBytes(row));</span><br><span class="line">		deleteList.add(delete);</span><br><span class="line">	&#125;</span><br><span class="line">	hTable.delete(deleteList);</span><br><span class="line">	hTable.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-7-获取所有数据"><a href="#6-2-7-获取所有数据" class="headerlink" title="6.2.7 获取所有数据"></a>6.2.7 获取所有数据</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getAllRows</span><span class="params">(String tableName)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">	HTable hTable = <span class="keyword">new</span> HTable(conf, tableName);</span><br><span class="line">	<span class="comment">//得到用于扫描region的对象</span></span><br><span class="line">	Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">	<span class="comment">//使用HTable得到resultcanner实现类的对象</span></span><br><span class="line">	ResultScanner resultScanner = hTable.getScanner(scan);</span><br><span class="line">	<span class="keyword">for</span>(Result result : resultScanner)&#123;</span><br><span class="line">		Cell[] cells = result.rawCells();</span><br><span class="line">		<span class="keyword">for</span>(Cell cell : cells)&#123;</span><br><span class="line">			<span class="comment">//得到rowkey</span></span><br><span class="line">			System.out.println(<span class="string">&quot;行键:&quot;</span> + Bytes.toString(CellUtil.cloneRow(cell)));</span><br><span class="line">			<span class="comment">//得到列族</span></span><br><span class="line">			System.out.println(<span class="string">&quot;列族&quot;</span> + Bytes.toString(CellUtil.cloneFamily(cell)));</span><br><span class="line">			System.out.println(<span class="string">&quot;列:&quot;</span> + Bytes.toString(CellUtil.cloneQualifier(cell)));</span><br><span class="line">			System.out.println(<span class="string">&quot;值:&quot;</span> + Bytes.toString(CellUtil.cloneValue(cell)));</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-8-获取某一行数据"><a href="#6-2-8-获取某一行数据" class="headerlink" title="6.2.8 获取某一行数据"></a>6.2.8 获取某一行数据</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getRow</span><span class="params">(String tableName, String rowKey)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">	HTable table = <span class="keyword">new</span> HTable(conf, tableName);</span><br><span class="line">	Get get = <span class="keyword">new</span> Get(Bytes.toBytes(rowKey));</span><br><span class="line">	<span class="comment">//get.setMaxVersions();显示所有版本</span></span><br><span class="line">    <span class="comment">//get.setTimeStamp();显示指定时间戳的版本</span></span><br><span class="line">	Result result = table.get(get);</span><br><span class="line">	<span class="keyword">for</span>(Cell cell : result.rawCells())&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;行键:&quot;</span> + Bytes.toString(result.getRow()));</span><br><span class="line">		System.out.println(<span class="string">&quot;列族&quot;</span> + Bytes.toString(CellUtil.cloneFamily(cell)));</span><br><span class="line">		System.out.println(<span class="string">&quot;列:&quot;</span> + Bytes.toString(CellUtil.cloneQualifier(cell)));</span><br><span class="line">		System.out.println(<span class="string">&quot;值:&quot;</span> + Bytes.toString(CellUtil.cloneValue(cell)));</span><br><span class="line">		System.out.println(<span class="string">&quot;时间戳:&quot;</span> + cell.getTimestamp());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6-2-9-获取某一行指定“列族-列”的数据"><a href="#6-2-9-获取某一行指定“列族-列”的数据" class="headerlink" title="6.2.9 获取某一行指定“列族:列”的数据"></a>6.2.9 获取某一行指定“列族:列”的数据</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getRowQualifier</span><span class="params">(String tableName, String rowKey, String family, String</span></span></span><br><span class="line"><span class="function"><span class="params"> qualifier)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">	HTable table = <span class="keyword">new</span> HTable(conf, tableName);</span><br><span class="line">	Get get = <span class="keyword">new</span> Get(Bytes.toBytes(rowKey));</span><br><span class="line">	get.addColumn(Bytes.toBytes(family), Bytes.toBytes(qualifier));</span><br><span class="line">	Result result = table.get(get);</span><br><span class="line">	<span class="keyword">for</span>(Cell cell : result.rawCells())&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;行键:&quot;</span> + Bytes.toString(result.getRow()));</span><br><span class="line">		System.out.println(<span class="string">&quot;列族&quot;</span> + Bytes.toString(CellUtil.cloneFamily(cell)));</span><br><span class="line">		System.out.println(<span class="string">&quot;列:&quot;</span> + Bytes.toString(CellUtil.cloneQualifier(cell)));</span><br><span class="line">		System.out.println(<span class="string">&quot;值:&quot;</span> + Bytes.toString(CellUtil.cloneValue(cell)));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6-3-MapReduce"><a href="#6-3-MapReduce" class="headerlink" title="6.3 MapReduce"></a>6.3 MapReduce</h4><p>通过HBase的相关JavaAPI，我们可以实现伴随HBase操作的MapReduce过程，比如使用MapReduce将数据从本地文件系统导入到HBase的表中，比如我们从HBase中读取一些原始数据后使用MapReduce做数据分析。</p><h5 id="6-3-1-官方HBase-MapReduce"><a href="#6-3-1-官方HBase-MapReduce" class="headerlink" title="6.3.1 官方HBase-MapReduce"></a>6.3.1 官方HBase-MapReduce</h5><ol><li><p><strong>查看HBase的MapReduce任务的执行</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> bin/hbase mapredcp</span></span><br></pre></td></tr></table></figure></li><li><p><strong>环境变量的导入</strong></p><p>(1) 执行环境变量的导入（临时生效，在命令行执行下述操作）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> HBASE_HOME=/opt/module/hbase-1.3.1</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-2.7.2</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> HADOOP_CLASSPATH=`<span class="variable">$&#123;HBASE_HOME&#125;</span>/bin/hbase mapredcp`</span></span><br></pre></td></tr></table></figure><p>(2) 永久生效：在/etc/profile配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_HOME=/opt/module/hbase-1.3.1</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br></pre></td></tr></table></figure><p>并在hadoop-env.sh中配置：(注意：在for循环之后配)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/opt/module/hbase/lib/*</span><br></pre></td></tr></table></figure></li></ol><ol start="3"><li><strong>运行官方的MapReduce任务</strong></li></ol><p>​ – 案例一：统计Student表中有多少行数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> /opt/module/hadoop-2.7.2/bin/yarn jar lib/hbase-server-1.3.1.jar rowcounter student</span></span><br></pre></td></tr></table></figure><p>​ – 案例二：使用MapReduce将本地数据导入到HBase</p><p>​ (1) 在本地创建一个tsv格式的文件：fruit.tsv</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1001	Apple	Red</span><br><span class="line">1002	Pear		Yellow</span><br><span class="line">1003	Pineapple	Yellow</span><br></pre></td></tr></table></figure><p>​ (2) 创建HBase表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; create &#39;fruit&#39;,&#39;info&#39;</span><br></pre></td></tr></table></figure><p>​ (3) 在HDFS中创建input_fruit文件夹并上传fruit.tsv文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> /opt/module/hadoop-2.7.2/bin/hdfs dfs -mkdir /input_fruit/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> /opt/module/hadoop-2.7.2/bin/hdfs dfs -put fruit.tsv /input_fruit/</span></span><br></pre></td></tr></table></figure><p>​ (4) 执行MapReduce到HBase的fruit表中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;bin&#x2F;yarn jar lib&#x2F;hbase-server-1.3.1.jar importtsv \</span><br><span class="line">-Dimporttsv.columns&#x3D;HBASE_ROW_KEY,info:name,info:color fruit \</span><br><span class="line">hdfs:&#x2F;&#x2F;hadoop102:9000&#x2F;input_fruit</span><br></pre></td></tr></table></figure><p>​ (5) 使用scan命令查看导入后的结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; scan ‘fruit’</span><br></pre></td></tr></table></figure><h5 id="6-3-2-自定义HBase-MapReduce1"><a href="#6-3-2-自定义HBase-MapReduce1" class="headerlink" title="6.3.2 自定义HBase-MapReduce1"></a>6.3.2 自定义HBase-MapReduce1</h5><p>目标：将fruit表中的一部分数据，通过MR迁入到fruit_mr表中。</p><p>分步实现：</p><p><strong>1．构建ReadFruitMapper类，用于读取fruit表中的数据</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Result;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReadFruitMapper</span> <span class="keyword">extends</span> <span class="title">TableMapper</span>&lt;<span class="title">ImmutableBytesWritable</span>, <span class="title">Put</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(ImmutableBytesWritable key, Result value, Context context)</span> </span></span><br><span class="line"><span class="function">	<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">	<span class="comment">//将fruit的name和color提取出来，相当于将每一行数据读取出来放入到Put对象中。</span></span><br><span class="line">		Put put = <span class="keyword">new</span> Put(key.get());</span><br><span class="line">		<span class="comment">//遍历添加column行</span></span><br><span class="line">		<span class="keyword">for</span>(Cell cell: value.rawCells())&#123;</span><br><span class="line">			<span class="comment">//添加/克隆列族:info</span></span><br><span class="line">			<span class="keyword">if</span>(<span class="string">&quot;info&quot;</span>.equals(Bytes.toString(CellUtil.cloneFamily(cell))))&#123;</span><br><span class="line">				<span class="comment">//添加/克隆列：name</span></span><br><span class="line">				<span class="keyword">if</span>(<span class="string">&quot;name&quot;</span>.equals(Bytes.toString(CellUtil.cloneQualifier(cell))))&#123;</span><br><span class="line">					<span class="comment">//将该列cell加入到put对象中</span></span><br><span class="line">					put.add(cell);</span><br><span class="line">					<span class="comment">//添加/克隆列:color</span></span><br><span class="line">				&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;color&quot;</span>.equals(Bytes.toString(CellUtil.cloneQualifier(cell))))&#123;</span><br><span class="line">					<span class="comment">//向该列cell加入到put对象中</span></span><br><span class="line">					put.add(cell);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//将从fruit读取到的每行数据写入到context中作为map的输出</span></span><br><span class="line">		context.write(key, put);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2． 构建WriteFruitMRReducer类，用于将读取到的fruit表中的数据写入到fruit_mr表中</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.hbase_mr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableReducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteFruitMRReducer</span> <span class="keyword">extends</span> <span class="title">TableReducer</span>&lt;<span class="title">ImmutableBytesWritable</span>, <span class="title">Put</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(ImmutableBytesWritable key, Iterable&lt;Put&gt; values, Context context)</span> </span></span><br><span class="line"><span class="function">	<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">		<span class="comment">//读出来的每一行数据写入到fruit_mr表中</span></span><br><span class="line">		<span class="keyword">for</span>(Put put: values)&#123;</span><br><span class="line">			context.write(NullWritable.get(), put);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>3．构建Fruit2FruitMRRunner extends Configured implements Tool用于组装运行Job任务</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//组装Job</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="comment">//得到Configuration</span></span><br><span class="line">		Configuration conf = <span class="keyword">this</span>.getConf();</span><br><span class="line">		<span class="comment">//创建Job任务</span></span><br><span class="line">		Job job = Job.getInstance(conf, <span class="keyword">this</span>.getClass().getSimpleName());</span><br><span class="line">		job.setJarByClass(Fruit2FruitMRRunner.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">//配置Job</span></span><br><span class="line">		Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">		scan.setCacheBlocks(<span class="keyword">false</span>);</span><br><span class="line">		scan.setCaching(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">//设置Mapper，注意导入的是mapreduce包下的，不是mapred包下的，后者是老版本</span></span><br><span class="line">		TableMapReduceUtil.initTableMapperJob(</span><br><span class="line">		<span class="string">&quot;fruit&quot;</span>, <span class="comment">//数据源的表名</span></span><br><span class="line">		scan, <span class="comment">//scan扫描控制器</span></span><br><span class="line">		ReadFruitMapper.class,<span class="comment">//设置Mapper类</span></span><br><span class="line">		ImmutableBytesWritable.class,<span class="comment">//设置Mapper输出key类型</span></span><br><span class="line">		Put.class,<span class="comment">//设置Mapper输出value值类型</span></span><br><span class="line">		job<span class="comment">//设置给哪个JOB</span></span><br><span class="line">		);</span><br><span class="line">		<span class="comment">//设置Reducer</span></span><br><span class="line">		TableMapReduceUtil.initTableReducerJob(<span class="string">&quot;fruit_mr&quot;</span>, WriteFruitMRReducer.class, job);</span><br><span class="line">		<span class="comment">//设置Reduce数量，最少1个</span></span><br><span class="line">		job.setNumReduceTasks(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">boolean</span> isSuccess = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">		<span class="keyword">if</span>(!isSuccess)&#123;</span><br><span class="line">			<span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;Job running with error&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> isSuccess ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><p><strong>4．主函数中调用运行该Job任务</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">Configuration conf = HBaseConfiguration.create();</span><br><span class="line"><span class="keyword">int</span> status = ToolRunner.run(conf, <span class="keyword">new</span> Fruit2FruitMRRunner(), args);</span><br><span class="line">System.exit(status);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>5．打包运行任务</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;bin&#x2F;yarn jar ~&#x2F;softwares&#x2F;jars&#x2F;hbase-0.0.1-SNAPSHOT.jar com.z.hbase.mr1.Fruit2FruitMRRunner</span><br></pre></td></tr></table></figure><p><font color="red">提示</font>：运行任务前，如果待数据导入的表不存在，则需要提前创建。</p><p><font color="red">提示</font>：maven打包命令：-P local clean package或-P dev clean package install（将第三方jar包一同打包，需要插件：maven-shade-plugin）</p><h5 id="6-3-3-自定义HBase-MapReduce2"><a href="#6-3-3-自定义HBase-MapReduce2" class="headerlink" title="6.3.3 自定义HBase-MapReduce2"></a>6.3.3 自定义HBase-MapReduce2</h5><p>目标：实现将HDFS中的数据写入到HBase表中。</p><p>分步实现：</p><p><strong>1．构建ReadFruitFromHDFSMapper于读取HDFS中的文件数据</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReadFruitFromHDFSMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">ImmutableBytesWritable</span>, <span class="title">Put</span>&gt; </span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">		<span class="comment">//从HDFS中读取的数据</span></span><br><span class="line">		String lineValue = value.toString();</span><br><span class="line">		<span class="comment">//读取出来的每行数据使用\t进行分割，存于String数组</span></span><br><span class="line">		String[] values = lineValue.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//根据数据中值的含义取值</span></span><br><span class="line">		String rowKey = values[<span class="number">0</span>];</span><br><span class="line">		String name = values[<span class="number">1</span>];</span><br><span class="line">		String color = values[<span class="number">2</span>];</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//初始化rowKey</span></span><br><span class="line">		ImmutableBytesWritable rowKeyWritable = <span class="keyword">new</span> ImmutableBytesWritable(Bytes.toBytes(rowKey));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//初始化put对象</span></span><br><span class="line">		Put put = <span class="keyword">new</span> Put(Bytes.toBytes(rowKey));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//参数分别:列族、列、值  </span></span><br><span class="line">        put.add(Bytes.toBytes(<span class="string">&quot;info&quot;</span>), Bytes.toBytes(<span class="string">&quot;name&quot;</span>),  Bytes.toBytes(name)); </span><br><span class="line">        put.add(Bytes.toBytes(<span class="string">&quot;info&quot;</span>), Bytes.toBytes(<span class="string">&quot;color&quot;</span>),  Bytes.toBytes(color)); </span><br><span class="line">        </span><br><span class="line">        context.write(rowKeyWritable, put);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>2．构建WriteFruitMRFromTxtReducer类</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.z.hbase.mr2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableReducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteFruitMRFromTxtReducer</span> <span class="keyword">extends</span> <span class="title">TableReducer</span>&lt;<span class="title">ImmutableBytesWritable</span>, <span class="title">Put</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(ImmutableBytesWritable key, Iterable&lt;Put&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">		<span class="comment">//读出来的每一行数据写入到fruit_hdfs表中</span></span><br><span class="line">		<span class="keyword">for</span>(Put put: values)&#123;</span><br><span class="line">			context.write(NullWritable.get(), put);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>3．创建Txt2FruitRunner组装Job</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">//得到Configuration</span></span><br><span class="line">Configuration conf = <span class="keyword">this</span>.getConf();</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建Job任务</span></span><br><span class="line">Job job = Job.getInstance(conf, <span class="keyword">this</span>.getClass().getSimpleName());</span><br><span class="line">job.setJarByClass(Txt2FruitRunner.class);</span><br><span class="line">Path inPath = <span class="keyword">new</span> Path(<span class="string">&quot;hdfs://hadoop102:9000/input_fruit/fruit.tsv&quot;</span>);</span><br><span class="line">FileInputFormat.addInputPath(job, inPath);</span><br><span class="line"></span><br><span class="line"><span class="comment">//设置Mapper</span></span><br><span class="line">job.setMapperClass(ReadFruitFromHDFSMapper.class);</span><br><span class="line">job.setMapOutputKeyClass(ImmutableBytesWritable.class);</span><br><span class="line">job.setMapOutputValueClass(Put.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//设置Reducer</span></span><br><span class="line">TableMapReduceUtil.initTableReducerJob(<span class="string">&quot;fruit_mr&quot;</span>, WriteFruitMRFromTxtReducer.class, job);</span><br><span class="line"></span><br><span class="line"><span class="comment">//设置Reduce数量，最少1个</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">boolean</span> isSuccess = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"><span class="keyword">if</span>(!isSuccess)&#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;Job running with error&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> isSuccess ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>4．调用执行Job</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		Configuration conf = HBaseConfiguration.create();</span><br><span class="line">	    <span class="keyword">int</span> status = ToolRunner.run(conf, <span class="keyword">new</span> Txt2FruitRunner(), args);</span><br><span class="line">	    System.exit(status);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>5．打包运行</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> /opt/module/hadoop-2.7.2/bin/yarn jar hbase-0.0.1-SNAPSHOT.jar com.atguigu.hbase.mr2.Txt2FruitRunner</span></span><br></pre></td></tr></table></figure><p>提示：运行任务前，如果待数据导入的表不存在，则需要提前创建之。</p><p>提示：maven打包命令：-P local clean package或-P dev clean package install（将第三方jar包一同打包，需要插件：maven-shade-plugin）</p><h4 id="6-4-与Hive的集成"><a href="#6-4-与Hive的集成" class="headerlink" title="6.4 与Hive的集成"></a>6.4 与Hive的集成</h4><h5 id="6-4-1-HBase与Hive的对比"><a href="#6-4-1-HBase与Hive的对比" class="headerlink" title="6.4.1 HBase与Hive的对比"></a>6.4.1 HBase与Hive的对比</h5><p><strong>1．Hive</strong></p><p>(1) 数据仓库</p><p>Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</p><p>(2) 用于数据分析、清洗</p><p>Hive适用于离线的数据分析和清洗，延迟较高。</p><p>(3) 基于HDFS、MapReduce</p><p>Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。</p><p><strong>2．HBase</strong></p><p>(1) 数据库</p><p>是一种面向列存储的非关系型数据库。</p><p>(2) 用于存储结构化和非结构化的数据</p><p>适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</p><p>(3) 基于HDFS</p><p>数据持久化存储的体现形式是Hfile，存放于DataNode中，被ResionServer以region的形式进行管理。</p><p>(4) 延迟较低，接入在线业务使用</p><p>面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p></div></article></div><div class="aside"><div class="box widget"><div class="introduction"><p><img src="/images/ironman.jpg" alt="head-sculpture"></p><p class="name">罗明辉Eric</p><p class="slogan">个人博客，分享经验，分享快乐</p></div></div><div class="box widget"><div class="title">最新</div><ul class="item-box"><li><a href="/2020/10/27/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></li><li><a href="/2020/09/03/ETL/Kettle/">Kettle</a></li><li><a href="/2020/08/10/BI/Tebleau/">Tebleau</a></li><li><a href="/2020/08/05/BI/PowerBI/">PowerBI</a></li><li><a href="/2020/07/28/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL%E8%AF%AD%E5%8F%A5%E8%B0%83%E4%BC%98/">SQL语句调优</a></li><li><a href="/2020/07/25/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%E5%8E%9F%E7%90%86/">Mysql底层原理</a></li><li><a href="/2020/07/15/BigDataFrame/HBase%E5%85%A5%E9%97%A8/">HBase入门</a></li><li><a href="/2020/07/05/BigDataFrame/Hive%E9%AB%98%E9%98%B6/">Hive高阶</a></li></ul></div><div class="box widget"><div class="title">分类</div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BI%E5%B7%A5%E5%85%B7/">BI工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ETL%E5%B7%A5%E5%85%B7/">ETL工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6/">大数据框架</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a><span class="category-list-count">1</span></li></ul></div><div class="box widget"><div class="title">归档</div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">2020-10</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">2020-09</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">2020-08</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">2020-07</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">2020-06</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">2020-01</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">2019-12</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">2019-07</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">2019-03</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">2018-09</a><span class="archive-list-count">1</span></li></ul></div></div></section><footer class="footer"><div class="global-width footer-box"><div class="copyright"><span>Copyright &copy; 2020</span> <span class="dotted">|</span> <span>Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a></span> <span class="dotted">|</span> <span>Theme by <a href="javascript:">Luominghui</a></span> <span class="dotted">|</span></div></div></footer></div><script>hljs.initHighlightingOnLoad()</script></body></html>